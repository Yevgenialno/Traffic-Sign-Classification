{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tunki\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "device=torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficData(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms=None):\n",
    "        self.image_ids = df['Path'].unique()\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index, size = [100, 100]):\n",
    "        image_path = self.image_ids[index]\n",
    "        records = self.df[self.df['Path'] == image_path]\n",
    "\n",
    "        #print(f'{self.image_dir}/{image_path}')\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_path}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, size)\n",
    "        image = image.astype(float) / 255.0\n",
    "\n",
    "        target = records['ClassId'].values\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(**image)\n",
    "\n",
    "        return image, target, image_path\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def create_dataset(df, dir, transform=None):\n",
    "       dataset = TrafficData(df, dir)\n",
    "       return dataset\n",
    "\n",
    "    @staticmethod \n",
    "    def loader(dataset, batch_size, num_workers=0):\n",
    "       data_loader = DataLoader(\n",
    "          dataset,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          num_workers=num_workers,\n",
    "          collate_fn = collate_fn\n",
    "      )\n",
    "       return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"Data_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_train = pd.DataFrame(columns=[\\'ClassId\\', \\'Path\\'])\\n\\ntrain_path = path / \\'Train\\'\\nfor folder in train_path.glob(\"*\"):\\n    #print(folder)\\n    class_id = int(str(folder)[len(str(train_path)) + 1:])\\n    for im in folder.glob(\"*\"):\\n        #print(p)\\n        df_train = pd.concat([df_train, pd.DataFrame({\\'ClassId\\': [class_id], \\'Path\\': [str(im)[len(str(path)) + 1:]]})], ignore_index=True)\\n        #df_train.loc[df_train.shape[0]] = [class_id, str(im)[len(str(path)) + 1:]]\\n\\ndf_train.to_csv(\"Data_images/Train_data.csv\")\\ndf_train.head()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6 minutes\n",
    "'''\n",
    "df_train = pd.DataFrame(columns=['ClassId', 'Path'])\n",
    "\n",
    "train_path = path / 'Train'\n",
    "for folder in train_path.glob(\"*\"):\n",
    "    #print(folder)\n",
    "    class_id = int(str(folder)[len(str(train_path)) + 1:])\n",
    "    for im in folder.glob(\"*\"):\n",
    "        #print(p)\n",
    "        df_train = pd.concat([df_train, pd.DataFrame({'ClassId': [class_id], 'Path': [str(im)[len(str(path)) + 1:]]})], ignore_index=True)\n",
    "        #df_train.loc[df_train.shape[0]] = [class_id, str(im)[len(str(path)) + 1:]]\n",
    "\n",
    "df_train.to_csv(\"Data_images/Train_data.csv\")\n",
    "df_train.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\RealProjects\\traffic_sign\\Data_Loaders.ipynb Ячейка 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/RealProjects/traffic_sign/Data_Loaders.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m pic \u001b[39min\u001b[39;00m test_path\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/RealProjects/traffic_sign/Data_Loaders.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(pic)[\u001b[39mlen\u001b[39m(\u001b[39mstr\u001b[39m(test_path)) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/RealProjects/traffic_sign/Data_Loaders.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     row \u001b[39m=\u001b[39m df_test_messy[df_test_messy[\u001b[39m'\u001b[39;49m\u001b[39mPath\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTest/\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/RealProjects/traffic_sign/Data_Loaders.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_test, row])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/RealProjects/traffic_sign/Data_Loaders.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_test\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mTest_data_cleaned.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3494\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3495\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[0;32m   3498\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3499\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3500\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3550\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3547\u001b[0m \u001b[39m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   3548\u001b[0m \u001b[39m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   3549\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[1;32m-> 3550\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39;49mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m   3551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "df_test_messy = pd.read_csv('Data_Images/Test_data.csv')\n",
    "df_test = pd.DataFrame(columns=['ClassId', 'Path'])\n",
    "\n",
    "test_path = path / 'Test'\n",
    "for pic in test_path.glob(\"*\"):\n",
    "    name = str(pic)[len(str(test_path)) + 1:]\n",
    "    row = df_test_messy[df_test_messy['Path'] == f'Test/{name}']\n",
    "    df_test = pd.concat([df_test, row])\n",
    "\n",
    "df_test.to_csv(\"Test_data_cleaned.csv\")\n",
    "df_test.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_test_messy.shape[0])\n",
    "#print(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data_Images/Train_data.csv\")\n",
    "df_test = pd.read_csv(\"Data_images/Test_data_cleaned.csv\")\n",
    "df_train = df_train[[\"ClassId\", \"Path\"]]\n",
    "df_test = df_test[[\"ClassId\", \"Path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrafficData.create_dataset(df_train, path)\n",
    "train_data_loader = TrafficData.loader(train_data, 16)\n",
    "\n",
    "test_data = TrafficData.create_dataset(df_test, path)\n",
    "test_data_loader = TrafficData.loader(test_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(test_data_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b9a10f91656d93d98ba8a913a134673a413a7bd9c9d8b98cc27e7c892521bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
